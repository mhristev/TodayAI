{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = downsampled_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"encoded_type\"]\n",
    "X = data.drop(columns=[\"encoded_type\", \"Length\", \"Duration\", \"Severity\", \"TrafficJamNum\", \"HectometerStart\", \"HectometerEnd\"] + list(data.select_dtypes(include=['object', 'datetime64', 'category']).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "   X[f\"shadow_{col}\"] = X[col].sample(frac=1).reset_index(drop=True)\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "def get_important_features(X, y):\n",
    "    # Initiliaze Random Forest CLassifier\n",
    "    rf = RandomForestClassifier(max_depth=20)\n",
    "    \n",
    "    # Fit Random Forest on provided data\n",
    "    rf.fit(X,y)\n",
    "    \n",
    "    # Create dictionary of feature importances\n",
    "    importances = {feature_name: f_importance for feature_name, f_importance in zip(X.columns, rf.feature_importances_)}\n",
    "    \n",
    "    # Isolate importances of Shadow features\n",
    "    only_shadow_feat_importance = {key:value for key,value in importances.items() if \"shadow\" in key}\n",
    "    \n",
    "    # get importance level of most important shadow feature\n",
    "    highest_shadow_feature = list(dict(sorted(only_shadow_feat_importance.items(), key=lambda item: item[1], reverse=True)).values())[0]\n",
    "    \n",
    "    # get original feature which fulfill boruta selection criteria\n",
    "    selected_features = [key for key, value in importances.items() if value > highest_shadow_feature]\n",
    "    \n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "patch_sklearn()\n",
    "\n",
    "TRIALS = 50\n",
    "feature_hits = {i:0 for i in data.columns}\n",
    "for _ in tqdm.tqdm(range(TRIALS)): \n",
    "    imp_features = get_important_features(X, y)\n",
    "    for key, _ in feature_hits.items(): \n",
    "        if key in imp_features: feature_hits[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-running the grid search on the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [],\n",
    "    'max_depth': [],\n",
    "    'min_samples_split': [],\n",
    "    'min_samples_leaf': [],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
